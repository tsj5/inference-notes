
@misc{:h,
  title = {Robust {{Predictable Control}}}
}

@inproceedings{Alemi:20,
  title = {Variational {{Predictive Information Bottleneck}}},
  booktitle = {Proceedings of {{The}} 2nd {{Symposium}} on  {{Advances}} in {{Approximate Bayesian Inference}}},
  year = {2020},
  month = feb,
  pages = {1--6},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {In classic papers, Zellner (1988, 2002) demonstrated that ayesian inference could be derived as the solution to an information theoretic functional. Below we derive a generalized form of this functional as a variational lower bound of a predictive information bottleneck objective. This generalized functional encompasses most modern inference procedures and suggests novel ones.},
  langid = {english},
  keywords = {VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/5768SKST/Variational Predictive Information Bottleneck-Alemi-2019.pdf;/Users/tsj/Documents/Zotero_finance/storage/FQRGPTDC/Variational Predictive Information Bottleneck-Alemi-2020.pdf},
  author = {Alemi, A. A.}
}

@misc{Alemi:21,
  title = {Demo {{Code}} for {{Deep Variational Information Bottleneck}}},
  year = {2021},
  month = nov,
  copyright = {Apache-2.0},
  author = {Alemi, A.}
}

@article{AlemiEtAl:16,
  title = {Deep {{Variational Information Bottleneck}}},
  year = {2016},
  month = nov,
  abstract = {Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.},
  langid = {english},
  keywords = {VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/2TQZVISE/Deep Variational Information Bottleneck-Alemi et al-2019.pdf;/Users/tsj/Documents/Zotero_finance/storage/LRZT7BDI/Alemi et al. - 2016 - Deep Variational Information Bottleneck.pdf},
  author = {Alemi, A. A. and Fischer, I. and Dillon, J. V. and Murphy, K.}
}

@article{AlemiFischer:18a,
  title = {{{TherML}}: {{Thermodynamics}} of {{Machine Learning}}},
  shorttitle = {{{TherML}}},
  year = {2018},
  month = oct,
  journal = {arXiv:1807.04162 [cond-mat, stat]},
  eprint = {1807.04162},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, stat},
  abstract = {In this work we offer a framework for reasoning about a wide class of existing objectives in machine learning. We develop a formal correspondence between this work and thermodynamics and discuss its implications.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Condensed Matter - Statistical Mechanics,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/N9D493CE/Alemi and Fischer - 2018 - TherML Thermodynamics of Machine Learning.pdf},
  author = {Alemi, A. A. and Fischer, I.}
}

@article{BanijamaliEtAl:18,
  title = {Deep {{Variational Sufficient Dimensionality Reduction}}},
  year = {2018},
  month = dec,
  journal = {arXiv:1812.07641 [cs, stat]},
  eprint = {1812.07641},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {We consider the problem of sufficient dimensionality reduction (SDR), where the high-dimensional observation is transformed to a low-dimensional sub-space in which the information of the observations regarding the label variable is preserved. We propose DVSDR, a deep variational approach for sufficient dimensionality reduction. The deep structure in our model has a bottleneck that represent the low-dimensional embedding of the data. We explain the SDR problem using graphical models and use the framework of variational autoencoders to maximize the lower bound of the log-likelihood of the joint distribution of the observation and label. We show that such a maximization problem can be interpreted as solving the SDR problem. DVSDR can be easily adopted to semi-supervised learning setting. In our experiment we show that DVSDR performs competitively on classification tasks while being able to generate novel data samples.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Important,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/RYVTEECR/Banijamali et al. - 2018 - Deep Variational Sufficient Dimensionality Reducti.pdf},
  author = {Banijamali, E. and Karimi, A.-H. and Ghodsi, A.}
}

@inproceedings{BelghaziEtAl:18,
  title = {Mutual {{Information Neural Estimation}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  year = {2018},
  month = jul,
  pages = {531--540},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neu...},
  langid = {english},
  keywords = {VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/HSKLB5ZW/Mutual Information Neural Estimation-Belghazi et al-2018.pdf;/Users/tsj/Documents/Zotero_finance/storage/LIUG5ERP/MINE-Belghazi et al-2018.pdf},
  author = {Belghazi, M. I. and Baratin, A. and Rajeshwar, S. and Ozair, S. and Bengio, Y. and Courville, A. and Hjelm, D.}
}

@article{BoydEtAl:17,
  title = {Multi-{{Period Trading}} via {{Convex Optimization}}},
  year = {2017},
  month = apr,
  journal = {arXiv:1705.00109 [math, q-fin]},
  eprint = {1705.00109},
  eprinttype = {arxiv},
  primaryclass = {math, q-fin},
  abstract = {We consider a basic model of multi-period trading, which can be used to evaluate the performance of a trading strategy. We describe a framework for single-period optimization, where the trades in each period are found by solving a convex optimization problem that trades off expected return, risk, transaction cost and holding cost such as the borrowing cost for shorting assets. We then describe a multi-period version of the trading method, where optimization is used to plan a sequence of trades, with only the first one executed, using estimates of future quantities that are unknown when the trades are chosen. The single-period method traces back to Markowitz; the multi-period methods trace back to model predictive control. Our contribution is to describe the single-period and multi-period methods in one simple framework, giving a clear description of the development and the approximations made. In this paper we do not address a critical component in a trading algorithm, the predictions or forecasts of future quantities. The methods we describe in this paper can be thought of as good ways to exploit predictions, no matter how they are made. We have also developed a companion open-source software library that implements many of the ideas and methods described in the paper.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {⛔ No DOI found,Mathematics - Optimization and Control,Quantitative Finance - Portfolio Management,VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/FAIDI5F4/Boyd et al. - 2017 - Multi-Period Trading via Convex Optimization.pdf;/Users/tsj/Documents/Zotero_finance/storage/IWL9XYCD/Boyd et al. - 2017 - Multi-Period Trading via Convex Optimization.pdf},
  author = {Boyd, S. and Busseti, E. and Diamond, S. and Kahn, R. N. and Koh, K. and Nystrup, P. and Speth, J.}
}

@book{Cesa-BianchiLugosi:06,
  title = {Prediction, {{Learning}}, and {{Games}}},
  year = {2006},
  month = mar,
  publisher = {{Cambridge University Press}},
  abstract = {This important text and reference for researchers and students in machine learning, game theory, statistics and information theory offers a comprehensive treatment of the problem of predicting individual sequences. Unlike standard statistical approaches to forecasting, prediction of individual sequences does not impose any probabilistic assumption on the data-generating mechanism. Yet, prediction algorithms can be constructed that work well for all possible sequences, in the sense that their performance is always nearly as good as the best forecasting strategy in a given reference class. The central theme is the model of prediction using expert advice, a general framework within which many related problems can be cast and discussed. Repeated game playing, adaptive data compression, sequential investment in the stock market, sequential pattern analysis, and several other problems are viewed as instances of the experts' framework and analyzed from a common nonstochastic standpoint that often reveals new and intriguing connections.},
  googlebooks = {zDnRBlazhfYC},
  isbn = {978-1-139-45482-7},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / Computer Vision \& Pattern Recognition,Computers / Optical Data Processing,Mathematics / Game Theory,Mathematics / Probability \& Statistics / General},
  file = {/Users/tsj/Documents/Zotero_finance/storage/TR22JDZR/Cesa-Bianchi and Lugosi - 2006 - Prediction, Learning, and Games.pdf},
  author = {{Cesa-Bianchi}, N. and Lugosi, G.}
}

@inproceedings{ChalkEtAl:16,
  title = {Relevant Sparse Codes with Variational Information Bottleneck},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  year = {2016},
  pages = {1957--1965},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/tsj/Documents/Zotero_finance/storage/9BGVMK42/Relevant sparse codes with variational information bottleneck-Chalk et al-2016.pdf;/Users/tsj/Documents/Zotero_finance/storage/I798KADY/Chalk et al. - 2016 - Relevant sparse codes with variational information.pdf},
  author = {Chalk, M. and Marre, O. and Tkacik, G.},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.}
}

@article{ChanEtAl:19,
  title = {Neural {{Entropic Estimation}}: {{A}} Faster Path to Mutual Information Estimation},
  shorttitle = {Neural {{Entropic Estimation}}},
  year = {2019},
  month = may,
  abstract = {We point out a limitation of the mutual information neural estimation (MINE) where the network fails to learn at the initial training phase, leading to slow convergence in the number of training iterations. To solve this problem, we propose a faster method called the mutual information neural entropic estimation (MI-NEE). Our solution first generalizes MINE to estimate the entropy using a custom reference distribution. The entropy estimate can then be used to estimate the mutual information. We argue that the seemingly redundant intermediate step of entropy estimation allows one to improve the convergence by an appropriate reference distribution. In particular, we show that MI-NEE reduces to MINE in the special case when the reference distribution is the product of marginal distributions, but faster convergence is possible by choosing the uniform distribution as the reference distribution instead. Compared to the product of marginals, the uniform distribution introduces more samples in low-density regions and fewer samples in high-density regions, which appear to lead to an overall larger gradient for faster convergence.},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/KP2GPPTD/Chan et al. - 2019 - Neural Entropic Estimation A faster path to mutua.pdf},
  author = {Chan, C. and {Al-Bashabsheh}, A. and Huang, H. P. and Lim, M. and Tam, D. S. H. and Zhao, C.}
}

@article{ChechikEtAl:05,
  title = {Information {{Bottleneck}} for {{Gaussian Variables}}},
  year = {2005},
  month = feb,
  journal = {Journal of Machine Learning Research},
  volume = {6},
  number = {Jan},
  pages = {165--188},
  file = {/Users/tsj/Documents/Zotero_finance/storage/AHQUZ6ZH/Information Bottleneck for Gaussian Variables-Chechik et al-2005.pdf},
  author = {Chechik, G. and Globerson, A. and Tishby, N. and Weiss, Y.}
}

@article{ChengEtAl:20,
  title = {{{CLUB}}: {{A Contrastive Log-ratio Upper Bound}} of {{Mutual Information}}},
  shorttitle = {{{CLUB}}},
  year = {2020},
  month = jul,
  journal = {arXiv:2006.12013 [cs, stat]},
  eprint = {2006.12013},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Mutual information (MI) minimization has gained considerable interests in various machine learning tasks. However, estimating and minimizing MI in high-dimensional spaces remains a challenging problem, especially when only samples, rather than distribution forms, are accessible. Previous works mainly focus on MI lower bound approximation, which is not applicable to MI minimization problems. In this paper, we propose a novel Contrastive Log-ratio Upper Bound (CLUB) of mutual information. We provide a theoretical analysis of the properties of CLUB and its variational approximation. Based on this upper bound, we introduce a MI minimization training scheme and further accelerate it with a negative sampling strategy. Simulation studies on Gaussian distributions show the reliable estimation ability of CLUB. Real-world MI minimization experiments, including domain adaptation and information bottleneck, demonstrate the effectiveness of the proposed method. The code is at https://github.com/Linear95/CLUB.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/WHH2DVGN/Cheng et al. - 2020 - CLUB A Contrastive Log-ratio Upper Bound of Mutua.pdf},
  author = {Cheng, P. and Hao, W. and Dai, S. and Liu, J. and Gan, Z. and Carin, L.}
}

@article{ChoiLee:20,
  title = {Regularized {{Mutual Information Neural Estimation}}},
  year = {2020},
  month = nov,
  eprint = {2011.07932},
  eprinttype = {arxiv},
  abstract = {With the variational lower bound of mutual information (MI), the estimation of MI can be understood as an optimization task via stochastic gradient descent. In this work, we start by showing how Mutual Information Neural Estimator (MINE) searches for the optimal function \$T\$ that maximizes the Donsker-Varadhan representation. With our synthetic dataset, we directly observe the neural network outputs during the optimization to investigate why MINE succeeds or fails: We discover the drifting phenomenon, where the constant term of \$T\$ is shifting through the optimization process, and analyze the instability caused by the interaction between the \$logsumexp\$ and the insufficient batch size. Next, through theoretical and experimental evidence, we propose a novel lower bound that effectively regularizes the neural network to alleviate the problems of MINE. We also introduce an averaging strategy that produces an unbiased estimate by utilizing multiple batches to mitigate the batch size limitation. Finally, we show that \$L\^2\$ regularization achieves significant improvements in both discrete and continuous settings.},
  archiveprefix = {arXiv},
  keywords = {Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/G6B99FP7/Choi and Lee - 2020 - Regularized Mutual Information Neural Estimation.pdf},
  author = {Choi, K. and Lee, S.}
}

@book{CoverThomas:91,
  title = {{{ELEMENTS OF INFORMATION THEORY}}},
  year = {1991},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/WS4C6D86/Cover and Thomas - ELEMENTS OF INFORMATION THEORY.pdf},
  author = {Cover, T. M. and Thomas, J. A.}
}

@article{EysenbachEtAl:21a,
  title = {Robust {{Predictable Control}}},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.03214 [cs]},
  eprint = {2109.03214},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Many of the challenges facing today's reinforcement learning (RL) algorithms, such as robustness, generalization, transfer, and computational efficiency are closely related to compression. Prior work has convincingly argued why minimizing information is useful in the supervised learning setting, but standard RL algorithms lack an explicit mechanism for compression. The RL setting is unique because (1) its sequential nature allows an agent to use past information to avoid looking at future observations and (2) the agent can optimize its behavior to prefer states where decision making requires few bits. We take advantage of these properties to propose a method (RPC) for learning simple policies. This method brings together ideas from information bottlenecks, model-based RL, and bits-back coding into a simple and theoretically-justified algorithm. Our method jointly optimizes a latent-space model and policy to be self-consistent, such that the policy avoids states where the model is inaccurate. We demonstrate that our method achieves much tighter compression than prior methods, achieving up to 5x higher reward than a standard information bottleneck. We also demonstrate that our method learns policies that are more robust and generalize better to new tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/UPAHLLBE/Eysenbach et al. - 2021 - Robust Predictable Control.pdf},
  author = {Eysenbach, B. and Salakhutdinov, R. and Levine, S.}
}

@article{Fischer:20,
  ids = {Fischer:20a},
  title = {The {{Conditional Entropy Bottleneck}}},
  year = {2020},
  month = sep,
  journal = {Entropy},
  volume = {22},
  number = {9},
  eprint = {2002.05379},
  eprinttype = {arxiv},
  pages = {999},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e22090999},
  abstract = {Much of the field of Machine Learning exhibits a prominent set of failure modes, including vulnerability to adversarial examples, poor out-of-distribution (OoD) detection, miscalibration, and willingness to memorize random labelings of datasets. We characterize these as failures of robust generalization, which extends the traditional measure of generalization as accuracy or related metrics on a held-out set. We hypothesize that these failures to robustly generalize are due to the learning systems retaining too much information about the training data. To test this hypothesis, we propose the Minimum Necessary Information (MNI) criterion for evaluating the quality of a model. In order to train models that perform well with respect to the MNI criterion, we present a new objective function, the Conditional Entropy Bottleneck (CEB), which is closely related to the Information Bottleneck (IB). We experimentally test our hypothesis by comparing the performance of CEB models with deterministic models and Variational Information Bottleneck (VIB) models on a variety of different datasets and robustness challenges. We find strong empirical evidence supporting our hypothesis that MNI models improve on these problems of robust generalization.},
  archiveprefix = {arXiv},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/tsj/Documents/Zotero_finance/storage/5V26BXQY/The Conditional Entropy Bottleneck-Fischer-2020.pdf;/Users/tsj/Documents/Zotero_finance/storage/9S97CCHN/Fischer - 2020 - The Conditional Entropy Bottleneck.pdf;/Users/tsj/Documents/Zotero_finance/storage/DPBI2UWQ/Fischer - 2020 - The Conditional Entropy Bottleneck.pdf;/Users/tsj/Documents/Zotero_finance/storage/RFSGUQK9/The Conditional Entropy Bottleneck-Fischer-2020.pdf},
  author = {Fischer, I.}
}

@article{FischerAlemi:20,
  title = {{{CEB Improves Model Robustness}}},
  year = {2020},
  month = sep,
  journal = {Entropy},
  volume = {22},
  number = {10},
  eprint = {2002.05380},
  eprinttype = {arxiv},
  pages = {1081},
  issn = {1099-4300},
  doi = {10/gk77v6},
  abstract = {We demonstrate that the Conditional Entropy Bottleneck (CEB) can improve model robustness. CEB is an easy strategy to implement and works in tandem with data augmentation procedures. We report results of a large scale adversarial robustness study on CIFAR-10, as well as the ImageNet-C Common Corruptions Benchmark, ImageNet-A, and PGD attacks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/2NKM6BLS/Fischer and Alemi - 2020 - CEB Improves Model Robustness.pdf},
  author = {Fischer, I. and Alemi, A. A.}
}

@article{GeigerFischer:20,
  title = {A {{Comparison}} of {{Variational Bounds}} for the {{Information Bottleneck Functional}}},
  year = {2020},
  month = nov,
  journal = {Entropy},
  volume = {22},
  number = {11},
  pages = {1229},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10/gn2zfz},
  abstract = {In this short note, we relate the variational bounds proposed in Alemi et al. (2017) and Fischer (2020) for the information bottleneck (IB) and the conditional entropy bottleneck (CEB) functional, respectively. Although the two functionals were shown to be equivalent, it was empirically observed that optimizing bounds on the CEB functional achieves better generalization performance and adversarial robustness than optimizing those on the IB functional. This work tries to shed light on this issue by showing that, in the most general setting, no ordering can be established between these variational bounds, while such an ordering can be enforced by restricting the feasible sets over which the optimizations take place. The absence of such an ordering in the general setup suggests that the variational bound on the CEB functional is either more amenable to optimization or a relevant cost function for optimization in its own regard, i.e., without justification from the IB or CEB functionals.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {deep learning,information bottleneck,neural networks},
  file = {/Users/tsj/Documents/Zotero_finance/storage/SU6E84XJ/Geiger and Fischer - 2020 - A Comparison of Variational Bounds for the Informa.pdf},
  author = {Geiger, B. C. and Fischer, I. S.}
}

@inproceedings{GhahramaniRasmussen:03,
  title = {Bayesian {{Monte Carlo}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  year = {2003},
  volume = {15},
  publisher = {{MIT Press}},
  keywords = {⛔ No DOI found},
  file = {/Users/tsj/Documents/Zotero_finance/storage/7G92CXRZ/Ghahramani and Rasmussen - 2003 - Bayesian Monte Carlo.pdf},
  author = {Ghahramani, Z. and Rasmussen, C.}
}

@article{GhoshEtAl:21,
  title = {Why {{Generalization}} in {{RL}} Is {{Difficult}}: {{Epistemic POMDPs}} and {{Implicit Partial Observability}}},
  shorttitle = {Why {{Generalization}} in {{RL}} Is {{Difficult}}},
  year = {2021},
  month = jul,
  journal = {arXiv:2107.06277 [cs, stat]},
  eprint = {2107.06277},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Generalization is a central challenge for the deployment of reinforcement learning (RL) systems in the real world. In this paper, we show that the sequential structure of the RL problem necessitates new approaches to generalization beyond the well-studied techniques used in supervised learning. While supervised learning methods can generalize effectively without explicitly accounting for epistemic uncertainty, we show that, perhaps surprisingly, this is not the case in RL. We show that generalization to unseen test conditions from a limited number of training conditions induces implicit partial observability, effectively turning even fully-observed MDPs into POMDPs. Informed by this observation, we recast the problem of generalization in RL as solving the induced partially observed Markov decision process, which we call the epistemic POMDP. We demonstrate the failure modes of algorithms that do not appropriately handle this partial observability, and suggest a simple ensemble-based technique for approximately solving the partially observed problem. Empirically, we demonstrate that our simple algorithm derived from the epistemic POMDP achieves significant gains in generalization over current methods on the Procgen benchmark suite.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/47MTS3JT/Ghosh et al. - 2021 - Why Generalization in RL is Difficult Epistemic P.pdf},
  author = {Ghosh, D. and Rahme, J. and Kumar, A. and Zhang, A. and Adams, R. P. and Levine, S.}
}

@article{GlobersonEtAl:12,
  title = {Sufficient {{Dimensionality Reduction}} with {{Irrelevant Statistics}}},
  year = {2012},
  month = oct,
  journal = {arXiv:1212.2483 [cs, stat]},
  eprint = {1212.2483},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {The problem of finding a reduced dimensionality representation of categorical variables while preserving their most relevant characteristics is fundamental for the analysis of complex data. Specifically, given a co-occurrence matrix of two variables, one often seeks a compact representation of one variable which preserves information about the other variable. We have recently introduced ``Sufficient Dimensionality Reduction' [GT-2003], a method that extracts continuous reduced dimensional features whose measurements (i.e., expectation values) capture maximal mutual information among the variables. However, such measurements often capture information that is irrelevant for a given task. Widely known examples are illumination conditions, which are irrelevant as features for face recognition, writing style which is irrelevant as a feature for content classification, and intonation which is irrelevant as a feature for speech recognition. Such irrelevance cannot be deduced apriori, since it depends on the details of the task, and is thus inherently ill defined in the purely unsupervised case. Separating relevant from irrelevant features can be achieved using additional side data that contains such irrelevant structures. This approach was taken in [CT-2002], extending the information bottleneck method, which uses clustering to compress the data. Here we use this side-information framework to identify features whose measurements are maximally informative for the original data set, but carry as little information as possible on a side data set. In statistical terms this can be understood as extracting statistics which are maximally sufficient for the original dataset, while simultaneously maximally ancillary for the side dataset. We formulate this tradeoff as a constrained optimization problem and characterize its solutions. We then derive a gradient descent algorithm for this problem, which is based on the Generalized Iterative Scaling method for finding maximum entropy distributions. The method is demonstrated on synthetic data, as well as on real face recognition datasets, and is shown to outperform standard methods such as oriented PCA.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found},
  file = {/Users/tsj/Documents/Zotero_finance/storage/PM8KA7JI/Sufficient Dimensionality Reduction with-Globerson et al-2012.pdf},
  author = {Globerson, A. and Chechik, G. and Tishby, N.}
}

@article{GlobersonTishby:03,
  title = {Sufficient Dimensionality Reduction},
  year = {2003},
  month = feb,
  journal = {jmlr.org},
  volume = {3},
  pages = {1307--1331},
  keywords = {Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/EE3CG7GM/Sufficient dimensionality reduction-Globerson_Tishby-2003.pdf},
  author = {Globerson, A. and Tishby, N.}
}

@article{GoldfeldPolyanskiy:20,
  title = {The {{Information Bottleneck Problem}} and Its {{Applications}} in {{Machine Learning}}},
  year = {2020},
  month = may,
  journal = {IEEE Journal on Selected Areas in Information Theory},
  volume = {1},
  number = {1},
  pages = {19--38},
  issn = {2641-8770},
  doi = {10.1109/JSAIT.2020.2991561},
  abstract = {Inference capabilities of machine learning (ML) systems skyrocketed in recent years, now playing a pivotal role in various aspect of society. The goal in statistical learning is to use data to obtain simple algorithms for predicting a random variable Y from a correlated observation X. Since the dimension of X is typically huge, computationally feasible solutions should summarize it into a lower-dimensional feature vector T, from which Y is predicted. The algorithm will successfully make the prediction if T is a good proxy of Y, despite the said dimensionality-reduction. A myriad of ML algorithms (mostly employing deep learning (DL)) for finding such representations T based on real-world data are now available. While these methods are effective in practice, their success is hindered by the lack of a comprehensive theory to explain it. The information bottleneck (IB) theory recently emerged as a bold information-theoretic paradigm for analyzing DL systems. Adopting mutual information as the figure of merit, it suggests that the best representation T should be maximally informative about Y while minimizing the mutual information with X. In this tutorial we survey the information-theoretic origins of this abstract principle, and its recent impact on DL. For the latter, we cover implications of the IB problem on DL theory, as well as practical algorithms inspired by it. Our goal is to provide a unified and cohesive description. A clear view of current knowledge is important for further leveraging IB and other information-theoretic ideas to study DL models.},
  keywords = {Deep learning,Important,information bottleneck,IP networks,machine learning,mutual information,Mutual information,neural networks,Noise measurement,Training},
  file = {/Users/tsj/Documents/Zotero_finance/storage/67F65JVZ/Goldfeld and Polyanskiy - 2020 - The Information Bottleneck Problem and its Applica.pdf;/Users/tsj/Documents/Zotero_finance/storage/A8J3QMDY/Goldfeld and Polyanskiy - 2020 - The Information Bottleneck Problem and its Applica.pdf},
  author = {Goldfeld, Z. and Polyanskiy, Y.}
}

@article{GoyalEtAl:19,
  title = {{{InfoBot}}: {{Transfer}} and {{Exploration}} via the {{Information Bottleneck}}},
  shorttitle = {{{InfoBot}}},
  year = {2019},
  month = apr,
  journal = {arXiv:1901.10902 [cs, stat]},
  eprint = {1901.10902},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {A central challenge in reinforcement learning is discovering effective policies for tasks where rewards are sparsely distributed. We postulate that in the absence of useful reward signals, an effective exploration strategy should seek out \{\textbackslash it decision states\}. These states lie at critical junctions in the state space from where the agent can transition to new, potentially unexplored regions. We propose to learn about decision states from prior experience. By training a goal-conditioned policy with an information bottleneck, we can identify decision states by examining where the model actually leverages the goal state. We find that this simple mechanism effectively identifies decision states, even in partially observed settings. In effect, the model learns the sensory cues that correlate with potential subgoals. In new environments, this model can then identify novel subgoals for further exploration, guiding the agent through a sequence of potential decision states and through new regions of the state space.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Statistics - Machine Learning,VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/ILLTMYVV/Goyal et al. - 2019 - InfoBot Transfer and Exploration via the Informat.pdf},
  author = {Goyal, A. and Islam, R. and Strouse, D. and Ahmed, Z. and Botvinick, M. and Larochelle, H. and Bengio, Y. and Levine, S.}
}

@article{GoyalEtAl:19a,
  title = {The {{Variational Bandwidth Bottleneck}}: {{Stochastic Evaluation}} on an {{Information Budget}}},
  shorttitle = {The {{Variational Bandwidth Bottleneck}}},
  year = {2019},
  month = sep,
  abstract = {Training agents with adaptive computation based on information bottleneck can promote generalization.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,VIP},
  file = {/Users/tsj/Documents/Zotero_finance/storage/IU7VC6RQ/Goyal et al. - 2019 - The Variational Bandwidth Bottleneck Stochastic E.pdf;/Users/tsj/Documents/Zotero_finance/storage/KKK9GXEP/Goyal et al. - 2020 - The Variational Bandwidth Bottleneck Stochastic E.pdf},
  author = {Goyal, A. and Bengio, Y. and Botvinick, M. and Levine, S.}
}

@misc{gustaf:21,
  title = {Mutual {{Information Neural Estimation}}},
  year = {2021},
  month = dec,
  abstract = {Mutual Information Neural Estimation in Pytorch},
  copyright = {MIT},
  author = {{gustaf}}
}

@article{HuangGamal:21,
  title = {A {{Provably Convergent Information Bottleneck Solution}} via {{ADMM}}},
  year = {2021},
  month = may,
  journal = {arXiv:2102.04729 [cs, math]},
  eprint = {2102.04729},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {The Information bottleneck (IB) method enables optimizing over the trade-off between compression of data and prediction accuracy of learned representations, and has successfully and robustly been applied to both supervised and unsupervised representation learning problems. However, IB has several limitations. First, the IB problem is hard to optimize. The IB Lagrangian \$\textbackslash mathcal\{L\}\_\{IB\}:=I(X;Z)-\textbackslash beta I(Y;Z)\$ is non-convex and existing solutions guarantee only local convergence. As a result, the obtained solutions depend on initialization. Second, the evaluation of a solution is also a challenging task. Conventionally, it resorts to characterizing the information plane, that is, plotting \$I(Y;Z)\$ versus \$I(X;Z)\$ for all solutions obtained from different initial points. Furthermore, the IB Lagrangian has phase transitions while varying the multiplier \$\textbackslash beta\$. At phase transitions, both \$I(X;Z)\$ and \$I(Y;Z)\$ increase abruptly and the rate of convergence becomes significantly slow for existing solutions. Recent works with IB adopt variational surrogate bounds to the IB Lagrangian. Although allowing efficient optimization, how close are these surrogates to the IB Lagrangian is not clear. In this work, we solve the IB Lagrangian using augmented Lagrangian methods. With augmented variables, we show that the IB objective can be solved with the alternating direction method of multipliers (ADMM). Different from prior works, we prove that the proposed algorithm is consistently convergent, regardless of the value of \$\textbackslash beta\$. Empirically, our gradient-descent-based method results in information plane points that are comparable to those obtained through the conventional Blahut-Arimoto-based solvers and is convergent for a wider range of the penalty coefficient than previous ADMM solvers.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Information Theory,Computer Science - Machine Learning,Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/4TVTSGGY/Huang and Gamal - 2021 - A Provably Convergent Information Bottleneck Solut.pdf},
  author = {Huang, T.-H. and Gamal, A. E.}
}

@article{KappenRuiz:16,
  title = {Adaptive {{Importance Sampling}} for {{Control}} and {{Inference}}},
  year = {2016},
  month = mar,
  journal = {J Stat Phys},
  volume = {162},
  number = {5},
  pages = {1244--1266},
  issn = {1572-9613},
  doi = {10.1007/s10955-016-1446-7},
  abstract = {Path integral (PI) control problems are a restricted class of non-linear control problems that can be solved formally as a Feynman\textendash Kac PI and can be estimated using Monte Carlo sampling. In this contribution we review PI control theory in the finite horizon case. We subsequently focus on the problem how to compute and represent control solutions. We review the most commonly used methods in robotics and control. Within the PI theory, the question of how to compute becomes the question of importance sampling. Efficient importance samplers are state feedback controllers and the use of these requires an efficient representation. Learning and representing effective state-feedback controllers for non-linear stochastic control problems is a very challenging, and largely unsolved, problem. We show how to learn and represent such controllers using ideas from the cross entropy method. We derive a gradient descent method that allows to learn feed-back controllers using an arbitrary parametrisation. We refer to this method as the path integral cross entropy method or PICE. We illustrate this method for some simple examples. The PI control methods can be used to estimate the posterior distribution in latent state models. In neuroscience these problems arise when estimating connectivity from neural recording data using EM. We demonstrate the PI control method as an accurate alternative to particle filtering.},
  langid = {english},
  keywords = {Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/YKQ65LQG/Kappen and Ruiz - 2016 - Adaptive Importance Sampling for Control and Infer.pdf},
  author = {Kappen, H. J. and Ruiz, H. C.}
}

@inproceedings{KolchinskyEtAl:18,
  ids = {KolchinskyEtAl:19},
  title = {Caveats for Information Bottleneck in Deterministic Scenarios},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  year = {2018},
  month = sep,
  eprint = {1808.07593},
  eprinttype = {arxiv},
  abstract = {Information bottleneck (IB) is a method for extracting information from one random variable X that is relevant for predicting another random variable Y. To do so, IB identifies an intermediate...},
  archiveprefix = {arXiv},
  file = {/Users/tsj/Documents/Zotero_finance/storage/4CLI3PPD/Caveats for information bottleneck in deterministic scenarios-Kolchinsky et al-2018.pdf;/Users/tsj/Documents/Zotero_finance/storage/9UKTEUPW/Caveats for information bottleneck in deterministic scenarios-Kolchinsky et al-2019.pdf;/Users/tsj/Documents/Zotero_finance/storage/AU9GYUJV/Caveats for information bottleneck in deterministic scenarios-Kolchinsky et al-2018.pdf;/Users/tsj/Documents/Zotero_finance/storage/NRWCG9J5/Caveats for information bottleneck in deterministic scenarios-Kolchinsky et al-2019.pdf;/Users/tsj/Documents/Zotero_finance/storage/QIXGDGNE/Caveats for information bottleneck in deterministic scenarios-Kolchinsky et al-2018.pdf;/Users/tsj/Documents/Zotero_finance/storage/UP8RIGNW/Caveats for information bottleneck in deterministic scenarios-Kolchinsky et al-2018.pdf},
  author = {Kolchinsky, A. and Tracey, B. D. and Kuyk, S. V.}
}

@article{LeeEtAl:20,
  title = {Predictive {{Information Accelerates Learning}} in {{RL}}},
  year = {2020},
  month = oct,
  journal = {arXiv:2007.12401 [cs, math, stat]},
  eprint = {2007.12401},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  abstract = {The Predictive Information is the mutual information between the past and the future, I(X\_past; X\_future). We hypothesize that capturing the predictive information is useful in RL, since the ability to model what will happen next is necessary for success on many tasks. To test our hypothesis, we train Soft Actor-Critic (SAC) agents from pixels with an auxiliary task that learns a compressed representation of the predictive information of the RL environment dynamics using a contrastive version of the Conditional Entropy Bottleneck (CEB) objective. We refer to these as Predictive Information SAC (PI-SAC) agents. We show that PI-SAC agents can substantially improve sample efficiency over challenging baselines on tasks from the DM Control suite of continuous control environments. We evaluate PI-SAC agents by comparing against uncompressed PI-SAC agents, other compressed and uncompressed agents, and SAC agents directly trained from pixels. Our implementation is given on GitHub.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Information Theory,Computer Science - Machine Learning,Computer Science - Robotics,Important,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/2YXTFNAB/Lee et al. - 2020 - Predictive Information Accelerates Learning in RL.pdf},
  author = {Lee, K.-H. and Fischer, I. and Liu, A. and Guo, Y. and Lee, H. and Canny, J. and Guadarrama, S.}
}

@article{LiaoEtAl:20,
  title = {{{DEMI}}: {{Discriminative Estimator}} of {{Mutual Information}}},
  shorttitle = {{{DEMI}}},
  year = {2020},
  month = nov,
  journal = {arXiv:2010.01766 [cs, stat]},
  eprint = {2010.01766},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Estimating mutual information between continuous random variables is often intractable and extremely challenging for high-dimensional data. Recent progress has leveraged neural networks to optimize variational lower bounds on mutual information. Although showing promise for this difficult problem, the variational methods have been theoretically and empirically proven to have serious statistical limitations: 1) many methods struggle to produce accurate estimates when the underlying mutual information is either low or high; 2) the resulting estimators may suffer from high variance. Our approach is based on training a classifier that provides the probability that a data sample pair is drawn from the joint distribution rather than from the product of its marginal distributions. Moreover, we establish a direct connection between mutual information and the average log odds estimate produced by the classifier on a test set, leading to a simple and accurate estimator of mutual information. We show theoretically that our method and other variational approaches are equivalent when they achieve their optimum, while our method sidesteps the variational bound. Empirical results demonstrate high accuracy of our approach and the advantages of our estimator in the context of representation learning. Our demo is available at https://github.com/RayRuizhiLiao/demi\_mi\_estimator.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/8CD4IIEL/Liao et al. - 2020 - DEMI Discriminative Estimator of Mutual Informati.pdf},
  author = {Liao, R. and Moyer, D. and Golland, P. and Wells, W. M.}
}

@article{LinEtAl:19,
  title = {Data-{{Efficient Mutual Information Neural Estimator}}},
  year = {2019},
  month = may,
  eprint = {1905.03319},
  eprinttype = {arxiv},
  abstract = {Measuring Mutual Information (MI) between high-dimensional, continuous, random variables from observed samples has wide theoretical and practical applications. Recent work, MINE (Belghazi et al. 2018), focused on estimating tight variational lower bounds of MI using neural networks, but assumed unlimited supply of samples to prevent overfitting. In real world applications, data is not always available at a surplus. In this work, we focus on improving data efficiency and propose a Data-Efficient MINE Estimator (DEMINE), by developing a relaxed predictive MI lower bound that can be estimated at higher data efficiency by orders of magnitudes. The predictive MI lower bound also enables us to develop a new meta-learning approach using task augmentation, Meta-DEMINE, to improve generalization of the network and further boost estimation accuracy empirically. With improved data-efficiency, our estimators enables statistical testing of dependency at practical dataset sizes. We demonstrate the effectiveness of our estimators on synthetic benchmarks and a real world fMRI data, with application of inter-subject correlation analysis.},
  archiveprefix = {arXiv},
  keywords = {Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/VH9GDC87/Lin et al. - 2019 - Data-Efficient Mutual Information Neural Estimator.pdf},
  author = {Lin, X. and Sur, I. and Nastase, S. A. and Divakaran, A. and Hasson, U. and Amer, M. R.}
}

@article{MarinariParisi:92,
  title = {Simulated {{Tempering}}: {{A New Monte Carlo Scheme}}},
  shorttitle = {Simulated {{Tempering}}},
  year = {1992},
  month = jul,
  journal = {EPL},
  volume = {19},
  number = {6},
  pages = {451--458},
  publisher = {{IOP Publishing}},
  issn = {0295-5075},
  doi = {10/bvn22s},
  abstract = {We propose a new global optimization method (Simulated Tempering) for simulating effectively a system with a rough free-energy landscape (i.e., many coexisting states) at finite nonzero temperature. This method is related to simulated annealing, but here the temperature becomes a dynamic variable, and the system is always kept at equilibrium. We analyse the method on the Random Field Ising Model, and we find a dramatic improvement over conventional Metropolis and cluster methods. We analyse and discuss the conditions under which the method has optimal performances.},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/RRU7U66A/Marinari and Parisi - 1992 - Simulated Tempering A New Monte Carlo Scheme.pdf},
  author = {Marinari, E. and Parisi, G.}
}

@inproceedings{McAllesterStratos:20,
  title = {Formal {{Limitations}} on the {{Measurement}} of {{Mutual Information}}},
  booktitle = {Proceedings of the {{Twenty Third International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  year = {2020},
  month = jun,
  pages = {875--884},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {Measuring mutual information from finite data is difficult. Recent work has considered variational methods maximizing a lower bound. In this paper, we prove that serious statistical limitations are inherent to any method of measuring mutual information. More specifically, we show that any distribution-free high-confidence lower bound on mutual information estimated from N samples cannot be larger than O(ln N).},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/3IT668P7/McAllester and Stratos - 2020 - Formal Limitations on the Measurement of Mutual In.pdf;/Users/tsj/Documents/Zotero_finance/storage/YABJ648Y/McAllester and Stratos - 2020 - Formal Limitations on the Measurement of Mutual In.pdf},
  author = {McAllester, D. and Stratos, K.}
}

@article{Neal:01,
  title = {Annealed Importance Sampling},
  year = {2001},
  month = apr,
  journal = {Statistics and Computing},
  volume = {11},
  number = {2},
  pages = {125--139},
  issn = {1573-1375},
  doi = {10/cgjxp4},
  abstract = {Simulated annealing\textemdash moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions\textemdash has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/CHXTYCJR/Neal - 2001 - Annealed importance sampling.pdf},
  author = {Neal, R. M.}
}

@article{NgampruetikornSchwab:21,
  title = {Perturbation {{Theory}} for the {{Information Bottleneck}}},
  year = {2021},
  month = oct,
  journal = {arXiv:2105.13977 [cond-mat, physics:physics]},
  eprint = {2105.13977},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, physics:physics},
  abstract = {Extracting relevant information from data is crucial for all forms of learning. The information bottleneck (IB) method formalizes this, offering a mathematically precise and conceptually appealing framework for understanding learning phenomena. However the nonlinearity of the IB problem makes it computationally expensive and analytically intractable in general. Here we derive a perturbation theory for the IB method and report the first complete characterization of the learning onset, the limit of maximum relevant information per bit extracted from data. We test our results on synthetic probability distributions, finding good agreement with the exact numerical solution near the onset of learning. We explore the difference and subtleties in our derivation and previous attempts at deriving a perturbation theory for the learning onset and attribute the discrepancy to a flawed assumption. Our work also provides a fresh perspective on the intimate relationship between the IB method and the strong data processing inequality.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Information Theory,Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Condensed Matter - Statistical Mechanics,Important,Physics - Data Analysis; Statistics and Probability},
  file = {/Users/tsj/Documents/Zotero_finance/storage/NJNVTZ5G/Ngampruetikorn and Schwab - 2021 - Perturbation Theory for the Information Bottleneck.pdf},
  author = {Ngampruetikorn, V. and Schwab, D. J.}
}

@inproceedings{NguyenEtAl:08,
  title = {Estimating Divergence Functionals and the Likelihood Ratio by Penalized Convex Risk Minimization},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  year = {2008},
  volume = {20},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/tsj/Documents/Zotero_finance/storage/Y5PSWM72/Nguyen et al. - 2008 - Estimating divergence functionals and the likeliho.pdf},
  author = {Nguyen, X. and Wainwright, M. J. and Jordan, M.}
}

@article{NguyenEtAl:10,
  title = {Estimating {{Divergence Functionals}} and the {{Likelihood Ratio}} by {{Convex Risk Minimization}}},
  year = {2010},
  month = nov,
  journal = {IEEE Transactions on Information Theory},
  volume = {56},
  number = {11},
  pages = {5847--5861},
  issn = {1557-9654},
  doi = {10.1109/TIT.2010.2068870},
  abstract = {We develop and analyze M-estimation methods for divergence functionals and the likelihood ratios of two probability distributions. Our method is based on a nonasymptotic variational characterization of f -divergences, which allows the problem of estimating divergences to be tackled via convex empirical risk optimization. The resulting estimators are simple to implement, requiring only the solution of standard convex programs. We present an analysis of consistency and convergence for these estimators. Given conditions only on the ratios of densities, we show that our estimators can achieve optimal minimax rates for the likelihood ratio and the divergence functionals in certain regimes. We derive an efficient optimization algorithm for computing our estimates, and illustrate their convergence behavior and practical viability by simulations.},
  keywords = {$f$-divergence,Convergence,Convex functions,Convex optimization,density ratio estimation,divergence estimation,Entropy,Estimation,Kernel,Kullback-Leibler (KL) divergence,M-estimation,Measurement,Probability distribution,reproducing kernel Hilbert space (RKHS),surrogate loss functions},
  file = {/Users/tsj/Documents/Zotero_finance/storage/QIIMJY9E/Nguyen et al. - 2010 - Estimating Divergence Functionals and the Likeliho.pdf},
  author = {Nguyen, X. and Wainwright, M. J. and Jordan, M. I.}
}

@article{NiEtAl:21,
  title = {Recurrent {{Model-Free RL}} Is a {{Strong Baseline}} for {{Many POMDPs}}},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.05038 [cs]},
  eprint = {2110.05038},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Many problems in RL, such as meta RL, robust RL, and generalization in RL, can be cast as POMDPs. In theory, simply augmenting model-free RL with memory, such as recurrent neural networks, provides a general approach to solving all types of POMDPs. However, prior work has found that such recurrent model-free RL methods tend to perform worse than more specialized algorithms that are designed for specific types of POMDPs. This paper revisits this claim. We find that careful architecture and hyperparameter decisions yield a recurrent model-free implementation that performs on par with (and occasionally substantially better than) more sophisticated recent techniques in their respective domains. We also release a simple and efficient implementation of recurrent model-free RL for future work to use as a baseline for POMDPs. Code is available at https://github.com/twni2016/pomdp-baselines},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/tsj/Documents/Zotero_finance/storage/V4CXTWMD/Ni et al. - 2021 - Recurrent Model-Free RL is a Strong Baseline for M.pdf},
  author = {Ni, T. and Eysenbach, B. and Salakhutdinov, R.}
}

@article{OordEtAl:16,
  title = {{{WaveNet}}: {{A Generative Model}} for {{Raw Audio}}},
  shorttitle = {{{WaveNet}}},
  year = {2016},
  month = sep,
  journal = {arXiv:1609.03499 [cs]},
  eprint = {1609.03499},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Computer Science - Sound},
  file = {/Users/tsj/Documents/Zotero_finance/storage/3R8JR85T/Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf},
  author = {van den Oord, A. and Dieleman, S. and Zen, H. and Simonyan, K. and Vinyals, O. and Graves, A. and Kalchbrenner, N. and Senior, A. and Kavukcuoglu, K.}
}

@article{OordEtAl:17,
  title = {Parallel {{WaveNet}}: {{Fast High-Fidelity Speech Synthesis}}},
  shorttitle = {Parallel {{WaveNet}}},
  year = {2017},
  month = nov,
  journal = {arXiv:1711.10433 [cs]},
  eprint = {1711.10433},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today's massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, and is deployed online by Google Assistant, including serving multiple English and Japanese voices.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/PPQHRWIA/Oord et al. - 2017 - Parallel WaveNet Fast High-Fidelity Speech Synthe.pdf},
  author = {van den Oord, A. and Li, Y. and Babuschkin, I. and Simonyan, K. and Vinyals, O. and Kavukcuoglu, K. and van den Driessche, G. and Lockhart, E. and Cobo, L. C. and Stimberg, F. and Casagrande, N. and Grewe, D. and Noury, S. and Dieleman, S. and Elsen, E. and Kalchbrenner, N. and Zen, H. and Graves, A. and King, H. and Walters, T. and Belov, D. and Hassabis, D.}
}

@article{OordEtAl:19,
  title = {Representation {{Learning}} with {{Contrastive Predictive Coding}}},
  year = {2019},
  month = jan,
  journal = {arXiv:1807.03748 [cs, stat]},
  eprint = {1807.03748},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/DHBBRD3X/Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf},
  author = {van den Oord, A. and Li, Y. and Vinyals, O.}
}

@article{Paninski:03,
  title = {Estimation of Entropy and Mutual Information},
  year = {2003},
  month = jun,
  journal = {Neural Comput.},
  volume = {15},
  number = {6},
  pages = {1191--1253},
  issn = {0899-7667},
  doi = {10.1162/089976603321780272},
  abstract = {We present some new results on the nonparametric estimation of entropy and mutual information. First, we use an exact local expansion of the entropy function to prove almost sure consistency and central limit theorems for three of the most commonly used discretized information estimators. The setup is related to Grenander's method of sieves and places no assumptions on the underlying probability measure generating the data. Second, we prove a converse to these consistency theorems, demonstrating that a misapplication of the most common estimation techniques leads to an arbitrarily poor estimate of the true information, even given unlimited data. This "inconsistency" theorem leads to an analytical approximation of the bias, valid in surprisingly small sample regimes and more accurate than the usual 1/N formula of Miller and Madow over a large region of parameter space. The two most practical implications of these results are negative: (1) information estimates in a certain data regime are likely contaminated by bias, even if "bias-corrected" estimators are used, and (2) confidence intervals calculated by standard techniques drastically underestimate the error of the most common estimation methods.Finally, we note a very useful connection between the bias of entropy estimators and a certain polynomial approximation problem. By casting bias calculation problems in this approximation theory framework, we obtain the best possible generalization of known asymptotic bias results. More interesting, this framework leads to an estimator with some nice properties: the estimator comes equipped with rigorous bounds on the maximum error over all possible underlying probability distributions, and this maximum error turns out to be surprisingly small. We demonstrate the application of this new estimator on both real and simulated data.},
  file = {/Users/tsj/Documents/Zotero_finance/storage/Q8VXVSUE/Estimation of entropy and mutual information-Paninski-2003.pdf},
  author = {Paninski, L.}
}

@article{PooleOzair:19,
  title = {On Variational Lower Bounds of Mutual Information},
  year = {2019},
  pages = {9},
  abstract = {Estimating and maximizing mutual information (MI) is core to many objectives in machine learning, but tractably lower bounding MI in high dimensions is challenging. Recent work has introduced variational lower bounds with neural networks to attack this problem, but the tradeoffs and relationships between these techniques remains unclear. Here, we present several results that begin to demystify these techniques: we show that the bias-corrected gradient in MINE (Belghazi et al., 2018) can be derived as an unbiased gradient of a new lower bound on MI, present a stabler Jensen-Shannon-based training algorithm for the critic, provide a new interpretation of contrastive predictive coding (CPC, van den Oord et al. (2018)) and prove this variant is a lower bound on MI, and demonstrate the batchsize dependence of CPC. Empirically, we show that the effectiveness of these bounds depends on properties of the data being modeled and the structure of the critic, with no one bound uniformly dominating.},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/FMHNCSYS/Poole and Ozair - On variational lower bounds of mutual information.pdf},
  author = {Poole, B. and Ozair, S.}
}

@article{ProppWilson:96,
  title = {Exact Sampling with Coupled {{Markov}} Chains and Applications to Statistical Mechanics},
  year = {1996},
  journal = {Random Structures \& Algorithms},
  volume = {9},
  number = {1-2},
  pages = {223--252},
  issn = {1098-2418},
  doi = {10/c9pks9},
  abstract = {For many applications it is useful to sample from a finite set of objects in accordance with some particular distribution. One approach is to run an ergodic (i.e., irreducible aperiodic) Markov chain whose stationary distribution is the desired distribution on this set; after the Markov chain has run for M steps, with M sufficiently large, the distribution governing the state of the chain approximates the desired distribution. Unfortunately, it can be difficult to determine how large M needs to be. We describe a simple variant of this method that determines on its own when to stop and that outputs samples in exact accordance with the desired distribution. The method uses couplings which have also played a role in other sampling schemes; however, rather than running the coupled chains from the present into the future, one runs from a distant point in the past up until the present, where the distance into the past that one needs to go is determined during the running of the algorithm itself. If the state space has a partial order that is preserved under the moves of the Markov chain, then the coupling is often particularly efficient. Using our approach, one can sample from the Gibbs distributions associated with various statistical mechanics models (including Ising, random-cluster, ice, and dimer) or choose uniformly at random from the elements of a finite distributive lattice. \textcopyright{} 1996 John Wiley \& Sons, Inc.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291098-2418\%28199608/09\%299\%3A1/2\%3C223\%3A\%3AAID-RSA14\%3E3.0.CO\%3B2-O},
  author = {Propp, J. G. and Wilson, D. B.}
}

@article{RodriguezGalvezEtAl:20,
  title = {The {{Convex Information Bottleneck Lagrangian}}},
  year = {2020},
  month = jan,
  journal = {Entropy},
  volume = {22},
  number = {1},
  pages = {98},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e22010098},
  abstract = {The information bottleneck (IB) problem tackles the issue of obtaining relevant compressed representations T of some random variable X for the task of predicting Y. It is defined as a constrained optimization problem that maximizes the information the representation has about the task,     I ( T ; Y )    , while ensuring that a certain level of compression r is achieved (i.e.,     I ( X ; T ) \&le; r    ). For practical reasons, the problem is usually solved by maximizing the IB Lagrangian (i.e.,      L IB   ( T ; \&beta; )  = I  ( T ; Y )  \&minus; \&beta; I  ( X ; T )     ) for many values of     \&beta; \&isin; [ 0 , 1 ]    . Then, the curve of maximal     I ( T ; Y )     for a given     I ( X ; T )     is drawn and a representation with the desired predictability and compression is selected. It is known when Y is a deterministic function of X, the IB curve cannot be explored and another Lagrangian has been proposed to tackle this problem: the squared IB Lagrangian:      L  sq \&minus; IB    ( T ;  \&beta; sq  )  = I  ( T ; Y )  \&minus;  \&beta; sq  I   ( X ; T )  2     . In this paper, we (i) present a general family of Lagrangians which allow for the exploration of the IB curve in all scenarios; (ii) provide the exact one-to-one mapping between the Lagrange multiplier and the desired compression rate r for known IB curve shapes; and (iii) show we can approximately obtain a specific compression level with the convex IB Lagrangian for both known and unknown IB curve shapes. This eliminates the burden of solving the optimization problem for many values of the Lagrange multiplier. That is, we prove that we can solve the original constrained problem with a single optimization.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {information bottleneck,mutual information,optimization,representation learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/CDCEG8UH/Rodríguez Gálvez et al. - 2020 - The Convex Information Bottleneck Lagrangian.pdf;/Users/tsj/Documents/Zotero_finance/storage/EUWEY4IC/Rodríguez Gálvez et al. - 2020 - The Convex Information Bottleneck Lagrangian.pdf},
  author = {Rodr{\'i}guez G{\'a}lvez, B. and Thobaben, R. and Skoglund, M.}
}

@article{SongErmon:20,
  title = {Understanding the {{Limitations}} of {{Variational Mutual Information Estimators}}},
  year = {2020},
  month = mar,
  journal = {arXiv:1910.06222 [cs, math, stat]},
  eprint = {1910.06222},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  abstract = {Variational approaches based on neural networks are showing promise for estimating mutual information (MI) between high dimensional variables. However, they can be difficult to use in practice due to poorly understood bias/variance tradeoffs. We theoretically show that, under some conditions, estimators such as MINE exhibit variance that could grow exponentially with the true amount of underlying MI. We also empirically demonstrate that existing estimators fail to satisfy basic self-consistency properties of MI, such as data processing and additivity under independence. Based on a unified perspective of variational approaches, we develop a new estimator that focuses on variance reduction. Empirical results on standard benchmark tasks demonstrate that our proposed estimator exhibits improved bias-variance trade-offs on standard benchmark tasks.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/GH2VGYFL/Song and Ermon - 2020 - Understanding the Limitations of Variational Mutua.pdf},
  author = {Song, J. and Ermon, S.}
}

@article{StrouseSchwab:17,
  title = {The {{Deterministic Information Bottleneck}}},
  year = {2017},
  month = jun,
  journal = {Neural Computation},
  volume = {29},
  number = {6},
  pages = {1611--1630},
  issn = {0899-7667},
  doi = {10/gbgzhn},
  abstract = {Lossy compression and clustering fundamentally involve a decision about which features are relevant and which are not. The information bottleneck method (IB) by Tishby, Pereira, and Bialek (1999) formalized this notion as an information-theoretic optimization problem and proposed an optimal trade-off between throwing away as many bits as possible and selectively keeping those that are most important. In the IB, compression is measured by mutual information. Here, we introduce an alternative formulation that replaces mutual information with entropy, which we call the deterministic information bottleneck (DIB) and argue better captures this notion of compression. As suggested by its name, the solution to the DIB problem turns out to be a deterministic encoder, or hard clustering, as opposed to the stochastic encoder, or soft clustering, that is optimal under the IB. We compare the IB and DIB on synthetic data, showing that the IB and DIB perform similarly in terms of the IB cost function, but that the DIB significantly outperforms the IB in terms of the DIB cost function. We also empirically find that the DIB offers a considerable gain in computational efficiency over the IB, over a range of convergence parameters. Our derivation of the DIB also suggests a method for continuously interpolating between the soft clustering of the IB and the hard clustering of the DIB.},
  file = {/Users/tsj/Documents/Zotero_finance/storage/3AAI453D/The deterministic information bottleneck-Strouse_Schwab-2016.pdf;/Users/tsj/Documents/Zotero_finance/storage/SSTUNXAQ/Strouse and Schwab - 2017 - The Deterministic Information Bottleneck.pdf},
  author = {Strouse, D. and Schwab, D. J.}
}

@article{TheodorouEtAl:10,
  title = {A {{Generalized Path Integral Control Approach}} to {{Reinforcement Learning}}},
  year = {2010},
  month = dec,
  journal = {J. Mach. Learn. Res.},
  volume = {11},
  pages = {3137--3181},
  issn = {1532-4435},
  abstract = {With the goal to generate more scalable algorithms with higher efficiency and fewer open parameters, reinforcement learning (RL) has recently moved towards combining classical techniques from optimal control and dynamic programming with modern learning techniques from statistical estimation theory. In this vein, this paper suggests to use the framework of stochastic optimal control with path integrals to derive a novel approach to RL with parameterized policies. While solidly grounded in value function estimation and optimal control based on the stochastic Hamilton-Jacobi-Bellman (HJB) equations, policy improvements can be transformed into an approximation problem of a path integral which has no open algorithmic parameters other than the exploration noise. The resulting algorithm can be conceived of as model-based, semi-model-based, or even model free, depending on how the learning problem is structured. The update equations have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Our new algorithm demonstrates interesting similarities with previous RL research in the framework of probability matching and provides intuition why the slightly heuristically motivated probability matching approach can actually perform well. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a simulated 12 degree-of-freedom robot dog illustrates the functionality of our algorithm in a complex robot learning scenario. We believe that Policy Improvement with Path Integrals (PI2) offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL based on trajectory roll-outs.},
  keywords = {Important},
  file = {/Users/tsj/Documents/Zotero_finance/storage/D6UQT3SZ/Theodorou et al. - A Generalized Path Integral Control Approach to Re.pdf;/Users/tsj/Documents/Zotero_finance/storage/P2QVY5SI/theodorou_erratum10a.pdf},
  author = {Theodorou, E. and Buchli, J. and Schaal, S.}
}

@inproceedings{TishbyEtAl:99,
  title = {The Information Bottleneck Method},
  booktitle = {The 37th {{Allerton Conference}} on {{Communications}}, {{Control}} and {{Computing}}},
  year = {1999},
  month = sep,
  pages = {368--377},
  publisher = {{Univ. of Illinois}},
  address = {{Urbana}},
  file = {/Users/tsj/Documents/Zotero_finance/storage/YJGCHGCB/The information bottleneck method-Tishby et al-2000.pdf},
  author = {Tishby, N. and Pereira, F. C. and Bialek, W.}
}

@inproceedings{WenEtAl:20,
  title = {Mutual {{Information Gradient Estimation}} for {{Representation Learning}}},
  booktitle = {{{arXiv}}:2005.01123 [Cs, Stat]},
  year = {2020},
  month = may,
  eprint = {2005.01123},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Mutual Information (MI) plays an important role in representation learning. However, MI is unfortunately intractable in continuous and high-dimensional settings. Recent advances establish tractable and scalable MI estimators to discover useful representation. However, most of the existing methods are not capable of providing an accurate estimation of MI with low-variance when the MI is large. We argue that directly estimating the gradients of MI is more appealing for representation learning than estimating MI in itself. To this end, we propose the Mutual Information Gradient Estimator (MIGE) for representation learning based on the score estimation of implicit distributions. MIGE exhibits a tight and smooth gradient estimation of MI in the high-dimensional and large-MI settings. We expand the applications of MIGE in both unsupervised learning of deep representations based on InfoMax and the Information Bottleneck method. Experimental results have indicated significant performance improvement in learning useful representation.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/tsj/Documents/Zotero_finance/storage/7H7YDJ6W/Wen et al. - 2019 - Mutual Information Gradient Estimation for Represe.pdf;/Users/tsj/Documents/Zotero_finance/storage/B9GILT6E/Wen et al. - 2020 - Mutual Information Gradient Estimation for Represe.pdf},
  author = {Wen, L. and Zhou, Y. and He, L. and Zhou, M. and Xu, Z.}
}

@inproceedings{WieczorekEtAl:18,
  title = {Learning {{Sparse Latent Representations}} with the {{Deep Copula Information Bottleneck}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  year = {2018},
  month = feb,
  abstract = {Deep latent variable models are powerful tools for representation learning. In this paper, we adopt the deep information bottleneck model, identify its shortcomings and propose a model that...},
  file = {/Users/tsj/Documents/Zotero_finance/storage/PA9ASZSE/Learning Sparse Latent Representations with the Deep Copula Information-Wieczorek et al-2018.pdf},
  author = {Wieczorek, A. and Wieser, M. and Murezzan, D. and Roth, V.}
}

@article{WieczorekRoth:20,
  title = {On the {{Difference}} between the {{Information Bottleneck}} and the {{Deep Information Bottleneck}}},
  year = {2020},
  month = feb,
  journal = {Entropy},
  volume = {22},
  number = {2},
  pages = {131},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e22020131},
  abstract = {Combining the information bottleneck model with deep learning by replacing mutual information terms with deep neural nets has proven successful in areas ranging from generative modelling to interpreting deep neural networks. In this paper, we revisit the deep variational information bottleneck and the assumptions needed for its derivation. The two assumed properties of the data, X and Y, and their latent representation T, take the form of two Markov chains     T \&minus; X \&minus; Y     and     X \&minus; T \&minus; Y    . Requiring both to hold during the optimisation process can be limiting for the set of potential joint distributions     P ( X , Y , T )    . We, therefore, show how to circumvent this limitation by optimising a lower bound for the mutual information between T and Y:     I ( T ; Y )    , for which only the latter Markov chain has to be satisfied. The mutual information     I ( T ; Y )     can be split into two non-negative parts. The first part is the lower bound for     I ( T ; Y )    , which is optimised in deep variational information bottleneck (DVIB) and cognate models in practice. The second part consists of two terms that measure how much the former requirement     T \&minus; X \&minus; Y     is violated. Finally, we propose interpreting the family of information bottleneck models as directed graphical models, and show that in this framework, the original and deep information bottlenecks are special cases of a fundamental IB model.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  file = {/Users/tsj/Documents/Zotero_finance/storage/EXY88WD4/Wieczorek and Roth - 2020 - On the Difference between the Information Bottlene.pdf},
  author = {Wieczorek, A. and Roth, V.}
}

@article{WuEtAl:19,
  ids = {WuEtAl:19b},
  title = {Learnability for the {{Information Bottleneck}}},
  year = {2019},
  month = sep,
  journal = {Entropy},
  volume = {21},
  number = {10},
  eprint = {1907.07331},
  eprinttype = {arxiv},
  pages = {924},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e21100924},
  abstract = {The Information Bottleneck (IB) method (\textbackslash cite\{tishby2000information\}) provides an insightful and principled approach for balancing compression and prediction for representation learning. The IB objective \$I(X;Z)-\textbackslash beta I(Y;Z)\$ employs a Lagrange multiplier \$\textbackslash beta\$ to tune this trade-off. However, in practice, not only is \$\textbackslash beta\$ chosen empirically without theoretical guidance, there is also a lack of theoretical understanding between \$\textbackslash beta\$, learnability, the intrinsic nature of the dataset and model capacity. In this paper, we show that if \$\textbackslash beta\$ is improperly chosen, learning cannot happen -- the trivial representation \$P(Z|X)=P(Z)\$ becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as \$\textbackslash beta\$ is varied. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, which provides theoretical guidance for choosing a good \$\textbackslash beta\$. We further show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the examples (the conspicuous subset), and discuss its relation with model capacity. We give practical algorithms to estimate the minimum \$\textbackslash beta\$ for a given dataset. We also empirically demonstrate our theoretical conditions with analyses of synthetic datasets, MNIST, and CIFAR10.},
  archiveprefix = {arXiv},
  keywords = {_tablet},
  file = {/Users/tsj/Documents/Zotero_finance/storage/FMK25JQA/Learnability for the Information Bottleneck-Wu et al-2019.pdf;/Users/tsj/Documents/Zotero_finance/storage/XXSL8Y6K/Learnability for the Information Bottleneck-Wu et al-2019.pdf},
  author = {Wu, T. and Fischer, I. and Chuang, I. L. and Tegmark, M.}
}


